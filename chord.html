<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Waveform Visualizer</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            text-align: center;
            background-color: #f0f2f5;
            margin: 0;
            padding: 20px;
            color: #333;
        }
        
        #chord {
            font-size: 1.2em;
            font-weight: bold;
            color: #2c3e50;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        }
        h1 {
            color: #2c3e50;
            margin-bottom: 30px;
        }
        .visualizer-container {
            position: relative;
            margin: 30px 0;
        }
        .visualizer {
            width: 100%;
            height: 200px;
            background-color: #f8f9fa;
            border-radius: 8px;
            overflow: hidden;
            border: 1px solid #e0e0e0;
        }
        canvas {
            display: block;
            width: 100%;
            height: 100%;
        }
        .audio-info {
            margin: 20px 0;
            padding: 15px;
            background-color: #e8f4fd;
            border-radius: 8px;
            text-align: left;
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 10px;
        }
        
        .chord-display {
            grid-column: span 2;
            text-align: center;
            padding: 15px;
            margin-top: 10px;
            background-color: #fff;
            border-radius: 5px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        }
        .visual-options {
            display: flex;
            flex-wrap: wrap;
            gap: 15px;
            justify-content: center;
            margin: 20px 0;
        }
        button {
            background-color: #3498db;
            color: white;
            border: none;
            padding: 12px 20px;
            font-size: 16px;
            border-radius: 5px;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        button:hover {
            background-color: #2980b9;
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        button:disabled {
            background-color: #95a5a6;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }
        select, input {
            padding: 10px;
            border-radius: 5px;
            border: 1px solid #ddd;
            font-size: 16px;
        }
        .color-picker {
            display: flex;
            align-items: center;
            gap: 10px;
        }
        .status {
            font-style: italic;
            color: #7f8c8d;
            margin: 10px 0;
        }
        .visualizer-overlay {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(255, 255, 255, 0.7);
            padding: 5px 10px;
            border-radius: 5px;
            font-size: 14px;
            pointer-events: none;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Guitar Chord & Waveform Visualizer v1</h1>
        
        <div class="status" id="status">Click "Start Listening" to begin</div>
        
        <div class="visualizer-container">
            <div class="visualizer">
                <canvas id="visualizer"></canvas>
            </div>
            <div class="visualizer-overlay" id="peak-meter">Peak: -∞ dB</div>
        </div>
        
        <div class="audio-info">
            <div id="frequency">Frequency: 0 Hz</div>
            <div id="volume">Volume: -∞ dB</div>
            <div id="note">Note: -</div>
            <div class="chord-display">
                <div id="chord">Chord: -</div>
            </div>
        </div>
        
        <div class="visual-options">
            <div>
                <label for="visualType">Visualization Type:</label>
                <select id="visualType">
                    <option value="waveform">Waveform</option>
                    <option value="bars">Frequency Bars</option>
                    <option value="circles">Circular Waves</option>
                </select>
            </div>
            
            <div class="color-picker">
                <label for="waveColor">Color:</label>
                <input type="color" id="waveColor" value="#3498db">
            </div>
        </div>
        
        <div>
            <button id="startButton">Start Listening</button>
            <button id="stopButton" disabled>Stop Listening</button>
        </div>
    </div>

    <script>
        // DOM Elements
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const statusElement = document.getElementById('status');
        const visualizer = document.getElementById('visualizer');
        const visualizerContext = visualizer.getContext('2d');
        const frequencyDisplay = document.getElementById('frequency');
        const volumeDisplay = document.getElementById('volume');
        const noteDisplay = document.getElementById('note');
        const chordDisplay = document.getElementById('chord');
        const peakMeterDisplay = document.getElementById('peak-meter');
        const visualTypeSelect = document.getElementById('visualType');
        const waveColorInput = document.getElementById('waveColor');
        
        // Music theory constants
        const NOTES = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
        const A4_FREQ = 440;
        const A4_INDEX = 69; // MIDI note number for A4
        
        // Common guitar chords and their component notes
        const CHORDS = {
            'C': ['C', 'E', 'G'],
            'Cm': ['C', 'D#', 'G'],
            'C7': ['C', 'E', 'G', 'A#'],
            'Cmaj7': ['C', 'E', 'G', 'B'],
            'D': ['D', 'F#', 'A'],
            'Dm': ['D', 'F', 'A'],
            'D7': ['D', 'F#', 'A', 'C'],
            'Dmaj7': ['D', 'F#', 'A', 'C#'],
            'E': ['E', 'G#', 'B'],
            'Em': ['E', 'G', 'B'],
            'E7': ['E', 'G#', 'B', 'D'],
            'Emaj7': ['E', 'G#', 'B', 'D#'],
            'F': ['F', 'A', 'C'],
            'Fm': ['F', 'G#', 'C'],
            'F7': ['F', 'A', 'C', 'D#'],
            'Fmaj7': ['F', 'A', 'C', 'E'],
            'G': ['G', 'B', 'D'],
            'Gm': ['G', 'A#', 'D'],
            'G7': ['G', 'B', 'D', 'F'],
            'Gmaj7': ['G', 'B', 'D', 'F#'],
            'A': ['A', 'C#', 'E'],
            'Am': ['A', 'C', 'E'],
            'A7': ['A', 'C#', 'E', 'G'],
            'Amaj7': ['A', 'C#', 'E', 'G#'],
            'B': ['B', 'D#', 'F#'],
            'Bm': ['B', 'D', 'F#'],
            'B7': ['B', 'D#', 'F#', 'A'],
            'Bmaj7': ['B', 'D#', 'F#', 'A#']
        };
        
        // Guitar standard tuning strings (from low to high): E2, A2, D3, G3, B3, E4
        const GUITAR_STRINGS = [
            { note: 'E', octave: 2 }, // E2
            { note: 'A', octave: 2 }, // A2
            { note: 'D', octave: 3 }, // D3
            { note: 'G', octave: 3 }, // G3
            { note: 'B', octave: 3 }, // B3
            { note: 'E', octave: 4 }  // E4
        ];
        
        // Audio processing variables
        let audioContext;
        let analyser;
        let microphone;
        let timeDataArray;
        let frequencyDataArray;
        let bufferLength;
        let isListening = false;
        let animationFrameId;
        let peakVolume = -Infinity;
        let peakDecay = 0.01; // How quickly the peak meter falls
        let activeNotes = new Set();
        let lastDetectedNotes = [];
        let lastClearTime = null;
        
        // Visualization options
        let visualType = 'waveform';
        let waveColor = '#3498db';
        
        // Set the correct dimensions for the canvas
        function setupCanvas() {
            // Get the actual size of the canvas element
            const rect = visualizer.getBoundingClientRect();
            
            // Set the canvas resolution to match its display size
            visualizer.width = rect.width * window.devicePixelRatio;
            visualizer.height = rect.height * window.devicePixelRatio;
            
            // Scale the context to normalize drawing
            visualizerContext.scale(window.devicePixelRatio, window.devicePixelRatio);
            
            console.log(`Canvas set up with dimensions: ${visualizer.width}x${visualizer.height}`);
        }
        
        // Convert frequency to note
        function frequencyToNote(frequency) {
            // First handle edge cases (extremely low or invalid frequencies)
            if (frequency <= 0 || !isFinite(frequency)) {
                return { note: "-", octave: 0, frequency: 0 };
            }
            
            // Calculate the number of half steps away from A4
            const halfStepsFromA4 = Math.round(12 * Math.log2(frequency / A4_FREQ));
            
            // Calculate MIDI note number
            const midiNoteNumber = A4_INDEX + halfStepsFromA4;
            
            // Calculate note and octave
            const noteIndex = ((midiNoteNumber % 12) + 12) % 12; // Ensure positive modulo
            const octave = Math.floor(midiNoteNumber / 12) - 1;
            
            // Log the conversion for debugging
            console.log(`Frequency ${frequency.toFixed(1)}Hz -> Note ${NOTES[noteIndex]}${octave}`);
            
            return {
                note: NOTES[noteIndex],
                octave: octave,
                frequency: frequency
            };
        }
        
        // Find the closest guitar string for a given frequency
        function findClosestGuitarString(noteInfo) {
            const { note, octave } = noteInfo;
            let closestString = null;
            let smallestDistance = Infinity;
            
            GUITAR_STRINGS.forEach((string, index) => {
                // Calculate "distance" based on note and octave
                const stringNoteIndex = NOTES.indexOf(string.note);
                const noteIndex = NOTES.indexOf(note);
                
                // Calculate total semitones for both
                const stringSemitones = string.octave * 12 + stringNoteIndex;
                const noteSemitones = octave * 12 + noteIndex;
                
                const distance = Math.abs(stringSemitones - noteSemitones);
                
                if (distance < smallestDistance) {
                    smallestDistance = distance;
                    closestString = {
                        string: index + 1, // 1-indexed for human readability
                        note: string.note,
                        octave: string.octave
                    };
                }
            });
            
            return closestString;
        }
        
        // Find possible chord based on detected notes
        function findPossibleChord(detectedNotes) {
            if (detectedNotes.length === 0) return null;
            if (detectedNotes.length === 1) return detectedNotes[0].note;
            
            // Extract just the note names (without octaves)
            const noteNames = detectedNotes.map(noteInfo => noteInfo.note);
            const uniqueNoteNames = [...new Set(noteNames)];
            
            // If we only have one unique note name, it's not a chord
            if (uniqueNoteNames.length === 1) return uniqueNoteNames[0];
            
            // Check each chord definition against our detected notes
            let bestMatch = null;
            let bestMatchCount = 0;
            let bestMatchName = null;
            
            for (const [chordName, chordNotes] of Object.entries(CHORDS)) {
                // Count how many of the chord's notes we've detected
                const matchedNotes = chordNotes.filter(note => uniqueNoteNames.includes(note));
                const matchCount = matchedNotes.length;
                
                // We'll relax our detection criteria to make it more sensitive
                // For a match, either:
                // 1. We should have at least 2 notes and they represent at least 50% of the chord
                // 2. We have a perfect match for a two-note chord
                const matchPercent = matchCount / chordNotes.length;
                
                if ((matchCount >= 2 && matchPercent >= 0.5) || 
                    (matchCount === 2 && chordNotes.length === 2) ||
                    (matchCount >= 3)) {
                    
                    // If this is a better match than our previous best, update
                    if (matchCount > bestMatchCount || 
                       (matchCount === bestMatchCount && matchPercent > bestMatch / chordNotes.length)) {
                        bestMatchCount = matchCount;
                        bestMatch = matchedNotes;
                        bestMatchName = chordName;
                    }
                }
            }
            
            // If we have 3 or more unique notes but couldn't find a chord match,
            // report it as an "Unknown" chord
            if (uniqueNoteNames.length >= 3 && !bestMatchName) {
                return "Unknown";
            }
            
            return bestMatchName || null;
        }
        
        // Find the dominant frequency
        function findDominantFrequency() {
            // Skip the first few bins (very low frequencies, often noise)
            let maxValue = -Infinity;
            let maxIndex = 0;
            
            // Start from bin 5 to avoid DC offset and very low frequencies
            for (let i = 5; i < bufferLength; i++) {
                if (frequencyDataArray[i] > maxValue) {
                    maxValue = frequencyDataArray[i];
                    maxIndex = i;
                }
            }
            
            // Convert bin index to frequency
            const frequency = maxIndex * audioContext.sampleRate / (analyser.fftSize * 2);
            return { frequency, magnitude: maxValue };
        }
        
        // Detect significant peaks in the frequency spectrum
        function detectFrequencyPeaks(threshold = -70) {
            const peaks = [];
            
            // Skip the very low frequency bins
            for (let i = 10; i < bufferLength / 2; i++) {
                // Only consider frequencies in the guitar range (approximately 80Hz to 1200Hz)
                const frequency = i * audioContext.sampleRate / analyser.fftSize;
                if (frequency < 80 || frequency > 1200) continue;
                
                // Check if this bin is a local maximum
                if (frequencyDataArray[i] > threshold && 
                    frequencyDataArray[i] > frequencyDataArray[i-1] && 
                    frequencyDataArray[i] > frequencyDataArray[i+1]) {
                    
                    // Check it's a genuine peak (compare with neighbors)
                    let isPeak = true;
                    for (let j = 2; j <= 3; j++) {
                        if (i-j >= 0 && frequencyDataArray[i] < frequencyDataArray[i-j]) {
                            isPeak = false;
                            break;
                        }
                        if (i+j < bufferLength && frequencyDataArray[i] < frequencyDataArray[i+j]) {
                            isPeak = false;
                            break;
                        }
                    }
                    
                    if (isPeak) {
                        const frequency = i * audioContext.sampleRate / analyser.fftSize;
                        peaks.push({
                            frequency,
                            magnitude: frequencyDataArray[i]
                        });
                    }
                }
            }
            
            // Sort by magnitude (strongest first)
            peaks.sort((a, b) => b.magnitude - a.magnitude);
            
            // Take top 4 peaks (typical for a guitar chord)
            return peaks.slice(0, 4);
        }
        
        // Calculate audio volume in dB
        function calculateVolume() {
            let sum = 0;
            
            // Sum the squares of all time domain samples
            for (let i = 0; i < bufferLength; i++) {
                const amplitude = (timeDataArray[i] / 128.0) - 1.0; // Convert to -1.0 to 1.0 range
                sum += amplitude * amplitude;
            }
            
            // Root mean square
            const rms = Math.sqrt(sum / bufferLength);
            
            // Convert to dB with proper handling of zero
            let db = rms > 0 ? 20 * Math.log10(rms) : -100;
            
            // Keep peak volume with decay
            if (db > peakVolume) {
                peakVolume = db;
            } else {
                peakVolume = Math.max(-100, peakVolume - peakDecay);
            }
            
            return { rms, db };
        }
        
        // Draw waveform visualization
        function drawWaveform() {
            // Clear the canvas
            visualizerContext.clearRect(0, 0, visualizer.width / window.devicePixelRatio, visualizer.height / window.devicePixelRatio);
            
            const width = visualizer.width / window.devicePixelRatio;
            const height = visualizer.height / window.devicePixelRatio;
            
            // Draw background
            visualizerContext.fillStyle = '#f8f9fa';
            visualizerContext.fillRect(0, 0, width, height);
            
            // Draw center line
            visualizerContext.beginPath();
            visualizerContext.strokeStyle = '#e0e0e0';
            visualizerContext.lineWidth = 1;
            visualizerContext.moveTo(0, height / 2);
            visualizerContext.lineTo(width, height / 2);
            visualizerContext.stroke();
            
            // Draw waveform
            visualizerContext.beginPath();
            visualizerContext.strokeStyle = waveColor;
            visualizerContext.lineWidth = 2;
            
            const sliceWidth = width / bufferLength;
            let x = 0;
            
            for (let i = 0; i < bufferLength; i++) {
                const v = timeDataArray[i] / 128.0;
                const y = v * height / 2;
                
                if (i === 0) {
                    visualizerContext.moveTo(x, y);
                } else {
                    visualizerContext.lineTo(x, y);
                }
                
                x += sliceWidth;
            }
            
            visualizerContext.stroke();
        }
        
        // Draw frequency bars visualization
        function drawFrequencyBars() {
            // Clear the canvas
            visualizerContext.clearRect(0, 0, visualizer.width / window.devicePixelRatio, visualizer.height / window.devicePixelRatio);
            
            const width = visualizer.width / window.devicePixelRatio;
            const height = visualizer.height / window.devicePixelRatio;
            
            // Draw background
            visualizerContext.fillStyle = '#f8f9fa';
            visualizerContext.fillRect(0, 0, width, height);
            
            // We'll only draw a subset of the frequency bins for better visualization
            const barCount = Math.min(bufferLength / 4, width / 2);
            const barWidth = width / barCount;
            
            // Draw frequency bars
            for (let i = 0; i < barCount; i++) {
                // Use a logarithmic distribution to show more detail in lower frequencies
                const barIndex = Math.floor(Math.pow(i / barCount, 2) * bufferLength);
                
                // Convert dB value to height (dB typically ranges from -100 to 0)
                const dbValue = frequencyDataArray[barIndex];
                const barHeight = ((dbValue + 100) / 100) * height;
                
                // Use a gradient based on frequency
                const hue = (i / barCount) * 220; // Blue to red spectrum
                visualizerContext.fillStyle = `hsl(${hue}, 80%, 60%)`;
                
                // Draw the bar
                visualizerContext.fillRect(i * barWidth, height - barHeight, barWidth - 1, barHeight);
            }
        }
        
        // Draw circular wave visualization
        function drawCircularWaves() {
            // Clear the canvas
            visualizerContext.clearRect(0, 0, visualizer.width / window.devicePixelRatio, visualizer.height / window.devicePixelRatio);
            
            const width = visualizer.width / window.devicePixelRatio;
            const height = visualizer.height / window.devicePixelRatio;
            
            // Draw background
            visualizerContext.fillStyle = '#f8f9fa';
            visualizerContext.fillRect(0, 0, width, height);
            
            const centerX = width / 2;
            const centerY = height / 2;
            const maxRadius = Math.min(width, height) * 0.4;
            
            // Sample points around a circle
            const numPoints = 100;
            const angleStep = (Math.PI * 2) / numPoints;
            
            // Create waveform based on frequency data
            visualizerContext.beginPath();
            
            for (let i = 0; i <= numPoints; i++) {
                const angle = i * angleStep;
                
                // Use frequency data to modify radius
                // We'll use a subset of frequency bins for better visualization
                const binIndex = Math.floor((i / numPoints) * (bufferLength / 2));
                
                // Normalize the frequency data (-100dB to 0dB range to 0-1)
                const frequencyMagnitude = (frequencyDataArray[binIndex] + 100) / 100;
                
                // Calculate radius with frequency influence
                const radius = maxRadius * (0.5 + frequencyMagnitude * 0.5);
                
                const x = centerX + radius * Math.cos(angle);
                const y = centerY + radius * Math.sin(angle);
                
                if (i === 0) {
                    visualizerContext.moveTo(x, y);
                } else {
                    visualizerContext.lineTo(x, y);
                }
            }
            
            visualizerContext.closePath();
            visualizerContext.strokeStyle = waveColor;
            visualizerContext.lineWidth = 2;
            visualizerContext.stroke();
            
            // Add inner circle
            visualizerContext.beginPath();
            visualizerContext.arc(centerX, centerY, maxRadius * 0.3, 0, Math.PI * 2);
            visualizerContext.fillStyle = `${waveColor}33`; // Add transparency
            visualizerContext.fill();
        }
        
        // Update the visualization based on current type
        function updateVisualization() {
            if (!isListening) return;
            
            // Get audio data
            analyser.getByteTimeDomainData(timeDataArray);
            analyser.getFloatFrequencyData(frequencyDataArray);
            
            // Find dominant frequency
            const { frequency, magnitude } = findDominantFrequency();
            
            // Calculate volume
            const { rms, db } = calculateVolume();
            
            // Perform note and chord detection
            // Use a more lenient threshold for detecting any sound
            if (db > -50) {
                // Get the note from the dominant frequency first
                const dominantNoteInfo = frequencyToNote(frequency);
                const closestString = findClosestGuitarString(dominantNoteInfo);
                
                // Always update the note display with what we're detecting
                // This provides immediate feedback even if it's not a strong signal
                noteDisplay.textContent = `Note: ${dominantNoteInfo.note}${dominantNoteInfo.octave}`;
                
                // Add note to active notes for chord detection if the signal is strong enough
                if (db > -40 && magnitude > -80) {
                    const noteKey = `${dominantNoteInfo.note}${dominantNoteInfo.octave}`;
                    
                    // Add to history with a simple debounce (only add if not just added)
                    if (!activeNotes.has(noteKey)) {
                        activeNotes.add(noteKey);
                        console.log(`Added note: ${noteKey} at ${frequency.toFixed(1)}Hz`);
                        
                        // Add to detected notes array
                        lastDetectedNotes.push(dominantNoteInfo);
                        
                        // Keep most recent notes (up to 6 for chord detection)
                        if (lastDetectedNotes.length > 6) {
                            lastDetectedNotes.shift();
                        }
                    }
                }
                
                // Try to detect a chord based on recent history
                if (lastDetectedNotes.length > 0) {
                    const possibleChord = findPossibleChord(lastDetectedNotes);
                    chordDisplay.textContent = `Chord: ${possibleChord || '-'}`;
                    
                    console.log("Active notes:", [...activeNotes]);
                    console.log("Last detected notes:", lastDetectedNotes.map(n => n.note));
                    console.log("Possible chord:", possibleChord);
                }
                
                // Clear stale notes after 2 seconds
                const currentTime = Date.now();
                if (!lastClearTime || (currentTime - lastClearTime > 2000)) {
                    activeNotes.clear();
                    lastClearTime = currentTime;
                }
            }
            
            // Update frequency and volume displays
            frequencyDisplay.textContent = `Frequency: ${frequency.toFixed(1)} Hz`;
            volumeDisplay.textContent = `Volume: ${db.toFixed(1)} dB`;
            peakMeterDisplay.textContent = `Peak: ${peakVolume.toFixed(1)} dB`;
            
            // Draw visualization based on selected type
            switch (visualType) {
                case 'waveform':
                    drawWaveform();
                    break;
                case 'bars':
                    drawFrequencyBars();
                    break;
                case 'circles':
                    drawCircularWaves();
                    break;
                default:
                    drawWaveform();
            }
            
            // Request next frame
            animationFrameId = requestAnimationFrame(updateVisualization);
        }
        
        // Start audio processing
        async function startAudioProcessing() {
            try {
                // Reset state
                activeNotes.clear();
                lastDetectedNotes = [];
                lastClearTime = null;
                
                // Set up the audio context
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                // Get access to the microphone
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                statusElement.textContent = "Listening to audio input...";
                
                // Create an audio source from the microphone
                microphone = audioContext.createMediaStreamSource(stream);
                
                // Create an analyser node - use a larger FFT size for better frequency resolution
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 4096; // Larger FFT size for better frequency resolution
                analyser.minDecibels = -100; // Increase sensitivity
                analyser.maxDecibels = -30;  // Adjust for typical guitar signal level
                analyser.smoothingTimeConstant = 0.8; // Smoothing for visualizations
                
                // Connect the microphone to the analyser
                microphone.connect(analyser);
                
                // Set up data arrays for time and frequency domain
                bufferLength = analyser.frequencyBinCount;
                timeDataArray = new Uint8Array(bufferLength);
                frequencyDataArray = new Float32Array(bufferLength);
                
                // Start the visualization
                setupCanvas();
                isListening = true;
                updateVisualization();
                
                // Update button states
                startButton.disabled = true;
                stopButton.disabled = false;
                
                console.log("Audio processing started with fftSize:", analyser.fftSize);
                console.log("Buffer length:", bufferLength);
                
            } catch (error) {
                console.error("Error accessing microphone:", error);
                statusElement.textContent = "Error: Could not access microphone. Please ensure your browser has permission to use it.";
            }
        }
        
        // Stop audio processing
        function stopAudioProcessing() {
            if (audioContext && audioContext.state !== 'closed') {
                // Stop animation
                if (animationFrameId) {
                    cancelAnimationFrame(animationFrameId);
                }
                
                // Disconnect microphone
                if (microphone) {
                    microphone.disconnect();
                }
                
                // Close audio context
                audioContext.close();
                
                // Update state
                isListening = false;
                statusElement.textContent = "Listening stopped.";
                
                // Update button states
                startButton.disabled = false;
                stopButton.disabled = true;
                
                // Clear visualizer
                visualizerContext.clearRect(0, 0, visualizer.width / window.devicePixelRatio, visualizer.height / window.devicePixelRatio);
                visualizerContext.fillStyle = '#f8f9fa';
                visualizerContext.fillRect(0, 0, visualizer.width / window.devicePixelRatio, visualizer.height / window.devicePixelRatio);
            }
        }
        
        // Event listeners
        startButton.addEventListener('click', startAudioProcessing);
        stopButton.addEventListener('click', stopAudioProcessing);
        
        // Handle visualization type changes
        visualTypeSelect.addEventListener('change', function() {
            visualType = this.value;
        });
        
        // Handle color changes
        waveColorInput.addEventListener('change', function() {
            waveColor = this.value;
        });
        
        // Handle window resize
        window.addEventListener('resize', function() {
            if (isListening) {
                setupCanvas();
            }
        });
        
        // Initial canvas setup
        setupCanvas();
    </script>
</body>
</html>
